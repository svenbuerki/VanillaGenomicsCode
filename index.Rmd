---
title: "Analytical workflow and code associated to *Vanilla* genomics analyses"
subtitle: ""
author: "Sven Buerki and Paige Ellestad - Boise State University"
date: "`r Sys.Date()`"
output:
#  bookdown::pdf_document2:
#    toc: TRUE
  bookdown::html_document2: 
    toc: TRUE
    toc_float: TRUE
    self_contained: TRUE
link-citations: yes
fontsize: 12pt
urlcolor: blue
csl: AmJBot.csl
bibliography: References.bib
editor_options: 
  markdown: 
    wrap: sentence
---

```{js logo-js, echo=FALSE}
$(document).ready(function() {
  $('#header').parent().prepend('<div id=\"logo\"><img src=\"Images/boisestate-primarylogo-2color-rgb.png\" style=\"position:absolute; top:0; right:0; padding:10px; height:120px\"></div>');
  $('#header').css('margin-right', '120px')
});
```

```{r packages, echo=FALSE, warning=FALSE, include=FALSE}
library(knitr)
library(rmarkdown)
library(bookdown)
#library(distill)
library(knitcitations)
library(formatR)
library(devtools)
library(kfigr)
library(dplyr)
library(kableExtra)
library(tufte)

#Generate BibTex citation file for all R packages used to produce report
knitr::write_bib(.packages(), file = 'packages.bib')
```

<div style="text-align: right"> [Download pdf version]() </div>
<div style="text-align: right"> [Raw data on GitHub](https://github.com/svenbuerki/VanillaGenomicsCode) </div>

# Introduction

This document provides the software, packages and code used to perform the genomic analyses described in Ellestad *et al.* (in prep.). All the analyses were performed on a Linux computer with the Ubuntu 18.04.6 LTS (GNU/Linux 4.15.0-177-generic x86_64) OS at Boise State University (ID, USA).

# Data

This project relies on pair-end Illumina short-read data (2x150bp) stored in `fastq` format and compressed using `gz` protocol. The data produced in this project will be deposited on NCBI under BioProject (pending). We are also using data from BioProject [PRJNA633886](https://www.ncbi.nlm.nih.gov/bioproject/PRJNA633886/) published in @Hasing2020.

# Project structure

Although the data underpinning the analyses are not presented here (due to size limitations), we are providing an overview of our project structure to facilitate understanding of the code (see Figure \@ref(fig:prjstr)).

```{r prjstr, echo=FALSE, fig.cap="Overview of the project structure applied to analyze data for the Vanilla genomics project.", out.width = '100%'}
knitr::include_graphics("Images/Project_str_VanillaCode.png")
```

A summary of the content of each folder is provided here (in alphabetical order):

- `Bowtie`: Contains `sam`, `bam`, `bcf` and `fa` files associated to read mapping analyses to assemble *Vanilla* genomes from Illumina short-read data using the *Vanilla planifolia* (Daphna) reference genome ([GCA_016413895.1](https://www.ncbi.nlm.nih.gov/data-hub/genome/GCA_016413895.1/)). 
- `DotPlot`: Contains `html` and `png` files associated to the dotplot analyses of the *Vanilla* genomes.
- `GenomeScope`: Contains GenomeScope output files (`png`) generated using output of the JellyFish analyses.
- `Heatmap`: Contains `csv` and `pdf` files associated to the percentage identity analyses at chromosome level.
- `JellyFish`: Contains the `histo` files associated to the k-mer frequency analyses conducted in JellyFish and used as input for the `GenomeScope` analyses.
- `Minimap2`: Contains the `paf` files from the `Minimap2` analyses used to conduct the dotplot, heatmap and genome coverage analyses.
- `Pafr`: Contains `pdf` files associated to the genome coverage maps inferred using `paf` files. This folder is entitled `Pafr` because the coverage maps are inferred using the r package *pafr*.
- `Raw_Data`: Contains `fastq.gz` files associated to the raw Illumina data used for this project.
- `Reference_genome`: Contains `fna` files for the *Vanilla planifolia* (Daphna) reference genome ([GCA_016413895.1](https://www.ncbi.nlm.nih.gov/data-hub/genome/GCA_016413895.1/)) as well as the index files for the read mapping analyses.
- `Smudgeplot`: Contains `kmctools` output files used for the Smudgeplot analyses.
- `Trimmomatic`: Contains `trimmed.fastq.gz` files used as input for the genomic analyses.


# Analytical pipeline

This section provides the code associated with the analyses aiming at comparing the genome complexity and structure of samples of *Vanilla planifolia* from Mexico and data available on NCBI. The following tasks are covered: 

1. Setting environment.
2. Downloading SRA files.
3. Conducting reads trimming.
4. Inferring genome size and heterozygosity.
5. Inferring ploidy and genome complexity.
6. Reconstructing genome sequences.
7. Testing for chromosomal structural re-arrangements and inferring percentage identities.

## Setting environment

Since these analyses are requiring a UNIX-based OS, we started by *i*) remotely accessing the Linux computer using `ssh` protocol (you need your user ID and IP address), *ii*) launching a `tmux` session (safe environment that can be accessed from different locations) and *iii*) navigating to project folder (here `Vanilla_SRA`) and *iv*) creating a variable with sample ID for analyses as follows:

```{bash echo=T, eval = F}
# 1. Remotely connect to computer using ssh (adjust with your credentials/IP)
ssh userID@IP

# 2. Start tmux session (to exit tmux session type Ctrl+b and d)
tmux

# 3.  Navigate to project location (adjust path)
cd /media/SeaGate/Vanilla_SRA/Raw_Data/
```

Further information on `ssh` and `tmux` protocols can be accessed [here](https://svenbuerki.github.io/Genomics-Bioinformatics/Tutorials.html).


## Downloading SRA files

Here, we need to *i*) create the `$SRA` variable with `SRA` accession number of data to be downloaded, *ii*) navigate to right folder (where data will be saved; here `Raw_Data/`) and *iii*) download `SRA` files (R1 and R2) using `parallel-fastq-dump`. This program allows parallelizing the downloading process and greatly reduces the downloading time. In this case, the files that we are downloading are compressed (`gz`) and they are in `fastq` format generated by Illumina instruments. The commands are available below:

```{bash echo = T, eval = F}
# 1. Create variable with sample SRA accession (as provided on NCBI)
SRA=SRR12628846 && # V. planifolia 'Hawaii'

# 2. Navigate to right location
cd Raw_Data/ &&

# 3. Download SRA files (R1 and R2) with parallelfastq (using 26 threads)
parallel-fastq-dump -O . --sra-id $SRA --threads 26 --split-files --gzip
```

`parallel-fastq-dump` is available on [GitHub](https://github.com/rvalieris/parallel-fastq-dump) and can be installed as follows:

```{bash echo = T, eval = F}
# Install program with Bioconda
conda install parallel-fastq-dump
```

## Conducting reads trimming

Here, we use `Trimmomatic` [@Bolger2014] to clean/trim the Illumina reads as follows:

```{bash echo = T, eval = F}
# 1. Navigate to right location
cd ../Trimmomatic &&

# 2. Conduct reads trimming
TrimmomaticPE -threads 30 /media/SeaGate/Vanilla_SRA/Raw_Data/"$SRA"_1.fastq.gz /media/SeaGate/Vanilla_SRA/Raw_Data/"$SRA"_2.fastq.gz "$SRA"_1_trimmed.fastq.gz "$SRA"_1_UNPAIRED.fastq.gz "$SRA"_2_trimmed.fastq.gz "$SRA"_2_UNPAIRED.fastq.gz LEADING:3 TRAILING:3 SLIDINGWINDOW:4:15 MINLEN:100
```

`Trimmomatic` is available on [GitHub](https://github.com/usadellab/Trimmomatic).

# References

<div id="refs"></div>

# Appendix 1 {.appendix}

Citations of all R packages used to generate this report. 

```{r generateBibliography, eval = T, results="asis", cache = F, echo=F, warning = FALSE, message=FALSE}
library("knitcitations")
cleanbib()
options("citation_format" = "pandoc")
read.bibtex(file = "packages.bib")
``` 
